Saltar para o conteúdo
Alternar barra lateral

Wikipédia
Pesquisar na Wikipédia
Criar uma conta

Ferramentas pessoais

ArtigoDiscussão
LerEditarVer histórico
Página principal
Conteúdo destacado
Eventos atuais
Esplanada
Página aleatória
Portais
Informar um erro
Colaboração
Boas-vindas
Ajuda
Página de testes
Portal comunitário
Mudanças recentes
Manutenção
Criar página
Páginas novas
Contato
Donativos
Ferramentas
Páginas afluentes
Alterações relacionadas
Carregar ficheiro
Páginas especiais
Hiperligação permanente
Informações da página
Citar esta página
Elemento Wikidata
Editar hiperligações interlínguas
Imprimir/exportar
Criar um livro
Descarregar como PDF
Versão para impressão
Noutros projetos
Wikimedia Commons
Idiomas
Nesta Wikipédia, os atalhos de idioma estão na parte superior da página, em frente ao título do artigo.
Banner logo	
De 4 de abril a 08 de julho de 2022

Inscreva-se aqui
[ocultar]

Ciência da computação
Origem: Wikipédia, a enciclopédia livre.
Disambig grey.svg Nota: Se procura a ramificação da Ciência da Computação, veja Teoria da computação. Se procura o termo geral, veja Computação.
Lambda maiúscila	Algoritmo de ordenação QuickSort
Utah teapot representing computer graphics	Mouse Microsoft Tastenmaus representando a interação humano-computador
A Ciência da Computação lida com fundamentos teóricos da informação, computação, e técnicas práticas para suas implementações e aplicações.
Ciência da computação é a ciência que estuda as técnicas, metodologias, instrumentos computacionais e aplicações tecnológicas, que informatizem os processos e desenvolvam soluções de processamento de dados de entrada e saída pautados no computador. Não se restringindo apenas ao estudo dos algoritmos, suas aplicações e implementação na forma de software. Assim, a Ciência da Computação também abrange as técnicas de modelagem de dados e gerenciamento de banco de dados, envolvendo também a telecomunicação e os protocolos de comunicação, além de princípios que abrangem outras especializações da área.[1]

Enquanto ciência, classifica-se como ciência exata, apesar de herdar elementos da lógica filosófica aristotélica, tendo por isto um papel importante na formalização matemática de algoritmos, como forma de representar problemas decidíveis, i.e., os que são susceptíveis de redução a operações elementares básicas, capazes de serem reproduzidas através de um dispositivo qualquer capaz de armazenar e manipular dados. Um destes dispositivos é o computador digital, de uso generalizado, nos dias de hoje. Também de fundamental importância para a área de Ciência da Computação são as metodologias e técnicas ligadas à implementação de software que abordam a especificação, modelagem, codificação, teste e avaliação de sistemas de software.

Os estudos oriundos da Ciência da Computação podem ser aplicados em qualquer área do conhecimento humano em que seja possível definir métodos de resolução de problemas baseados em repetições previamente observadas. Avanços recentes na Ciência da Computação têm impactado fortemente a sociedade contemporânea, em particular as aplicações relacionadas às áreas de redes de computadores, Internet, Web, ciência de dados e computação móvel, que têm sido utilizadas por bilhões de pessoas ao redor do globo.[2]


Índice
1	História da Computação
1.1	Algoritmos
1.2	Lógica binária
1.3	Engenho analítico
1.4	Nascimento da Ciência da Computação
1.5	Trabalho teórico
1.6	Shannon e a teoria da informação
2	Contribuição social
3	Pessoas notáveis
3.1	Precursores
3.2	Personalidades influentes
4	Áreas de pesquisa
4.1	Fundamentos matemáticos
4.2	Fundamentos de computação
4.3	Física
4.4	Tecnologia da computação
4.5	Ciência da computação aplicada
4.6	Organização dos sistemas computacionais
5	Relacionamento com outros campos
6	Profissão
7	Ver também
8	Referências
9	Ligações externas
História da Computação
Ver artigo principal: História da computação

O ábaco, primeira ferramenta de computação, em sua forma moderna.
A primeira ferramenta conhecida para a computação foi o ábaco,[3] cuja invenção é atribuída a habitantes da Mesopotâmia, em torno de 2700–2300 a.C.. Seu uso original era desenhar linhas na areia com rochas. Versões mais modernas do ábaco ainda são usadas como instrumento de cálculo.

No século VII a.C., na antiga Índia, o gramático Pānini formulou a gramática de Sânscrito usando 3959 regras conhecidas como Ashtadhyāyi, de forma bastante sistemática e técnica. Pānini usou transformações e recursividade com tamanha sofisticação que sua gramática possuía o poder computacional teórico tal qual a Máquina de Turing.

Entre 200 a.C. e 400, os indianos também inventaram o logaritmo, e a partir do século XIII tabelas logarítmicas eram produzidas por matemáticos islâmicos. Quando John Napier descobriu os logaritmos para uso computacional no século XVI,[3] seguiu-se um período de considerável progresso na construção de ferramentas de cálculo.


Al-Khwarizmi.
Algoritmos
No século VII, o matemático indiano Brahmagupta explicou pela primeira vez o sistema de numeração hindu-arábico e o uso do 0. Aproximadamente em 825, o matemático persa al-Khwarizmi escreveu o livro Calculando com numerais hindus, responsável pela difusão do sistema de numeração hindu-arábico no Oriente Médio, e posteriormente na Europa. Por volta do século XII houve uma tradução do mesmo livro para o latim: Algoritmi de numero Indorum. Tais livros apresentaram novos conceitos para definir sequências de passos para completar tarefas, como aplicações de aritmética e álgebra. Por derivação do nome do matemático, atualmente usa-se o termo algoritmo.

Lógica binária
Por volta do século III a.C., o matemático indiano Pingala inventou o sistema de numeração binário. Ainda usado atualmente no processamento de todos os computadores modernos, o sistema estabelece que sequências específicas de uns e zeros podem representar qualquer informação.

Em 1703 Gottfried Leibniz desenvolveu a lógica em um sentido formal e matemático, utilizando o sistema binário. Em seu sistema, uns e zeros também representam conceitos como verdadeiro e falso, ligado e desligado, válido e inválido. Mais de um século depois, George Boole publicou a álgebra booleana (em 1854), com um sistema completo que permitia a construção de modelos matemáticos para o processamento computacional. Em 1801, apareceu o tear controlado por cartão perfurado, invenção de Joseph Marie Jacquard, no qual buracos indicavam os uns e áreas não furadas indicavam os zeros. O sistema está longe de ser um computador, mas ilustrou que as máquinas poderiam ser controladas pelo sistema binário.

Engenho analítico

Ada Lovelace, primeira programadora.
Foi com Charles Babbage que o computador moderno começou a ganhar forma, através de seu trabalho no engenho analítico. O equipamento descrito originalmente em 1837, mais de um século antes de seu sucessor, nunca foi construído com sucesso, mas possuía todas as funções de um computador moderno. O dispositivo de Babbage se diferenciava por ser programável, algo imprescindível para qualquer computador moderno.

Durante sua colaboração, a matemática Ada Lovelace publicou os primeiros programas de computador em uma série de notas para o engenho analítico.[4] Por isso, Lovelace é popularmente considerada como a primeira programadora.

Nascimento da Ciência da Computação
Antes da década de 1920, computador era um termo associado a pessoas que realizavam cálculos, geralmente liderados por físicos. Milhares de computadores eram empregados em projetos no comércio, governo e sítios de pesquisa. Após a década de 1920, a expressão máquina computacional começou a ser usada para referir-se a qualquer máquina que realize o trabalho de um profissional, especialmente aquelas de acordo com os métodos da Tese de Church-Turing.

O termo máquina computacional acabou perdendo espaço para o termo reduzido computador no final da década de 1940, com as máquinas digitais cada vez mais difundidas. Alan Turing, conhecido como pai da Ciência da Computação, inventou a Máquina de Turing, que posteriormente evoluiu para o computador moderno.

Trabalho teórico
Os fundamentos matemáticos da Ciência da Computação moderna começaram a ser definidos por Kurt Gödel com seu teorema da incompletude (1931). Essa teoria mostra que existem limites no que pode ser provado ou desaprovado em um sistema formal; isso levou a trabalhos posteriores por Gödel e outros teóricos para definir e descrever tais sistemas formais, incluindo conceitos como recursividade e cálculo lambda.

Em 1936 Alan Turing e Alonzo Church independentemente, e também juntos, introduziram a formalização de um algoritmo, definindo os limites do que pode ser computador e um modelo puramente mecânico para a computação. Tais tópicos são abordados no que atualmente chama-se Tese de Church-Turing, uma hipótese sobre a natureza de dispositivos mecânicos de cálculo. Essa tese define que qualquer cálculo possível pode ser realizado por um algoritmo sendo executado em um computador, desde que haja tempo e armazenamento suficiente para tal.


Representação visual da Máquina de Turing
Turing também incluiu na tese uma descrição da Máquina de Turing, que possui uma fita de tamanho infinito e um cabeçote para leitura e escrita que move-se pela fita. Devido ao seu caráter infinito, tal máquina não pode ser construída, mas tal modelo pode simular a computação de qualquer algoritmo executado em um computador moderno. Turing é bastante importante para a Ciência da Computação, tanto que seu nome é usado para o Prêmio Turing e o teste de Turing. Ele contribuiu para a quebra do código da Alemanha pela Grã-Bretanha[5] na Segunda Guerra Mundial, e continuou a projetar computadores e programas de computador pela década de 1940; cometeu suicídio em 1954.[6][7]

Shannon e a teoria da informação
Até a década de 1930, engenheiros eletricistas podiam construir circuitos eletrônicos para resolver problemas lógicos e matemáticos, mas a maioria o fazia sem qualquer processo, de forma particular, sem rigor teórico para tal. Isso mudou com a tese de mestrado de Claude Shannon de 1937, A Symbolic Analysis of Relay and Switching Circuits. Enquanto tomava aulas de Filosofia, Shannon foi exposto ao trabalho de George Boole, e percebeu que poderia aplicar esse aprendizado em conjuntos eletro-mecânicos para resolver problemas. Shannon desenvolveu a teoria da informação no artigo de 1948: A Mathematical Theory of Communication,[8] cujo conteúdo serve como fundamento para áreas como compressão de dados e criptografia.[9]

Contribuição social
Apesar de sua pequena história enquanto uma disciplina acadêmica, a Ciência da Computação deu origem a diversas contribuições fundamentais para a ciência e para a sociedade. Esta ciência foi responsável pela definição formal de computação e computabilidade, e pela prova da existência de problemas insolúveis ou intratáveis computacionalmente.

[10] Também foi possível a construção e formalização do conceito de linguagem de computador, sobretudo linguagem de programação, uma ferramenta para a expressão precisa de informação metodológica flexível o suficiente para ser representada em diversos níveis de abstração.[11]

Para outros campos científicos e para a sociedade de forma geral, a Ciência da Computação forneceu suporte para a Revolução Digital, dando origem a Era da Informação.[10] A computação científica é uma área da computação que permite o avanço de estudos como o mapeamento do genoma humano (ver Projeto Genoma Humano).

Ciência da Computação tem tanto a ver com o computador como a astronomia com o telescópio, a biologia com o microscópio, ou a química com os tubos de ensaio. A ciência não estuda ferramentas, mas o que fazemos e o que descobrimos com elas.
— Citação atribuída a Edsger Dijkstra
Pessoas notáveis
Algumas das pessoas mais importantes da computação foram agraciadas com o Prêmio Turing.

Precursores
Blaise Pascal, desenvolveu a calculadora mecânica e tem seu nome em uma linguagem de programação;
Charles Babbage, projetou um computador mecânico, a máquina analítica;
Ada Lovelace, considerada a primeira pessoa programadora, deu nome a uma linguagem de programação;
Alan Turing, participou do projeto Colossus e foi um dos cérebros que decifra a Enigma. Também inventou um tipo teórico de máquina super-simples capaz de realizar qualquer cálculo de um computador digital, a Máquina de Turing;
John von Neumann, descreveu o computador que utiliza um programa armazenado em memória, a Arquitetura de von Neumann, que é a base da arquitetura dos computadores atuais;
John Backus, líder da equipe que criou o Fortran e criou a notação BNF;
Maurice Vicent Wilkes, inventor do somador binário;
Howard Aiken, inventor do Mark I;
Walter H. Brattain, inventor do transístor;
William Shockley, inventor do transístor;
John Bardeen, inventor do transístor;
Fred Williams, inventor da memória RAM;
Tom Kilburn, inventor da memória RAM;
Konrad Zuse, inventor independente do computador digital e de linguagens de programação na Alemanha nazista;
John Atanasoff, inventor do primeiro computador digital, o Atanasoff–Berry Computer, ABC;
Clifford Berry, assistente de Atanasoff;
Almirante Grace Hopper, programadora do Mark I, desenvolveu o primeiro compilador; primeira mulher a receber um Ph.D. em matemática;
Edsger Dijkstra, líder do ALGOL 60, publicou o artigo original sobre programação estruturada;
J. Presper Eckert, criador do ENIAC;
John William Mauchly, criador do ENIAC.
Personalidades influentes
Andrew Stuart Tanenbaum, pesquisador na área de sistemas operacionais, inventor do MINIX; seus livros-texto são dos mais referenciados na área;
Edgar Frank Codd, inventor de Banco de dados relacionais;
Brian Kernighan, inventor da linguagem de programação C;
Dennis Ritchie, inventor da linguagem de programação C e do Unix;
Bjarne Stroustrup, inventor da linguagem de programação C++;
Ken Thompson, inventor do Unix e da codificação de caracteres UTF-8;
Peter Chen, inventor do Modelo de entidades e relacionamentos;
Donald Ervin Knuth, criador do TeX, da programação literária e da influente série (inacabada em 2011) sobre algoritmos The Art of Computer Programming;
Richard Stallman, fundador do projeto GNU e idealizador da licença de software livre GPL;
Linus Torvalds, criador do núcleo Linux;
Alan Kay, um dos inventores da orientação a objeto, também concebeu o laptop e a interface gráfica do utilizador;
Steve Wozniak e Steve Jobs, criadores da Apple Inc., e do primeiro computador pessoal, o Apple I;
Bill Gates e Paul Allen, criadores da Microsoft, a empresa que criou o Windows;
James Gosling, criador da linguagem Java;
Guido van Rossum, criador da linguagem Python;
Tim Berners-Lee, criador da World Wide Web e do HTML;
Brendan Eich, criador do JavaScript.
Áreas de pesquisa
Fundamentos matemáticos
Álgebra linear
Cálculo diferencial e integral
Cálculo numérico
Analise combinatória
Geometria analítica — o estudo de algoritmos para a resolução de problemas de geometria, ou que dependem da geometria
Heurística - o desvendamento de soluções de problemas com alto grau de complexidade
Lógica matemática — lógica booleana e outras formas para a modelagem lógica de problemas
Matemática discreta
Teoria do caos - sistemas complexos e não determinísticos influenciam a confecção de novos algoritmos e metodologias matemáticas na computação
Probabilidade e estatística
Teoria da informação
Teoria das categorias
Teoria dos grafos — fundações para estruturas de dados e algoritmos de busca
Teoria dos números — teoria para a definição de provas a conjunto dos números inteiros, usada em criptografia e no teste de inteligência artificial
Teoria dos tipos — análise formal de tipos de dados e seu uso para entender a propriedade de programas de algoritmos
Fundamentos de computação
Paradigma de programação
Circuitos digitais
Complexidade computacional — definição de limites computacionais (sobretudo relativo a espaço e tempo) fundamentais em classes de computação
Criptografia — aplicação da complexidade computacional, da probabilidade e da teoria de números para a criação ou quebra de códigos
Estrutura de dados — a organização e as regras para a manipulação de informação
Linguagens formais — estudo de modelos para especificar e reconhecer linguagens de forma geral
Métodos formais — o uso de abordagens matemáticas para descrever e formalizar padrões de desenvolvimento de software
Pesquisa e ordenação
Projeto e análise de algoritmos — complexidade computacional aplicada aos algoritmos
Robótica — o controle do comportamento de robôs
Semântica formal — estudo da especificação do significado (ou comportamento) de programas de computador e partes de hardware
Teoria da computabilidade — definição do que é computável utilizando-se os modelos atuais, definindo as possibilidades teóricas da computação
Teoria da computação
Teoria dos algoritmos de informação
Teoria dos autômatos
Física
Eletromagnetismo
Mecânica quântica
Tecnologia da computação
Banco de dados
Compiladores — tradução de algoritmos entre diferentes linguagens de computador, geralmente de uma linguagem de alto nível, mais abstrata e legível para seres humanos, para uma linguagem de baixo nível, mais concreta e voltada para o computador digital
Computação gráfica — geração sintética de imagens, e a integração ou alteração visual de informações visuais do mundo real
Engenharia de software
Inteligência artificial — o estudo e a implementação de sistemas que exibem um comportamento autônomo inteligente
Microprocessamento - o estudo dos chips, circuitos integrados e sistemas digitais que interagem com as linguagens de baixo nível
Processamento de imagens — a obtenção de informação a partir de imagens
Rede de computadores — algoritmos e protocolos para a comunicação de dados confiável entre diferentes sistemas, incluindo mecanismos para a identificação e correção de erros
Sistemas operacionais - softwares básicos que gerenciam os recursos computacionais e fazem a interação entre hardware e software
Sistemas de Informação - todos os recursos em TI que servem para armazenar, manipular, transferir e tratar dados, sejam eles elementos computacionais ou não-computacionais
Ciência da computação aplicada
Álgebra computacional
Especificação de programas
Estrutura de dados
Informática educativa
Interação homem-computador — estudo sobre a utilidade e usabilidade de computadores, tornando-os acessíveis às pessoas
Otimização combinatória
Pesquisa operacional
Planejamento automatizado[12] — estuda o processo de deliberação por meio da computação
Programação de computadores — o uso de linguagens de programação para a implementação de algoritmos
Reconhecimento de padrões
Recuperação de informações
Redes de Petri
Redes neurais
Redes semânticas
Segurança de computadores
Sistemas multiagentes
Tolerância a falhas
Vida artificial — o estudo de organismos digitais
Organização dos sistemas computacionais
Arquitetura de computadores — o desenvolvimento, a organização, a otimização e a verificação de sistemas computacionais
Computação distribuída — computação sendo executada em diversos dispositivos interligados por uma rede, todos com o mesmo objetivo comum
Computação paralela — computação sendo executada em diferentes tarefas; geralmente concorrentes entre si na utilização de recursos
Computação quântica — representação e manipulação de dados usando as propriedades quânticas das partículas e a mecânica quântica
Sistemas operacionais — sistemas para o gerenciamento de programas de computador e para a abstração da máquina, fornecendo base para um sistema utilizável
Relacionamento com outros campos
Por ser uma disciplina recente, existem várias definições alternativas para a Ciência da Computação. Ela pode ser vista como uma forma de ciência, uma forma de matemática ou uma nova disciplina que não pode ser categorizada seguindo os modelos atuais. Várias pessoas que estudam a Ciência da Computação o fazem para tornarem-se programadores, levando alguns a acreditarem que seu estudo é sobre o software e a programação. Apesar disso, a maioria dos cientistas da computação são interessados na inovação ou em aspectos teóricos que vão muito além de somente a programação, mais relacionados com a computabilidade.

Apesar do nome, muito da Ciência da Computação não envolve o estudo dos computadores por si próprios. De fato, o conhecido cientista da computação Edsger Dijkstra é considerado autor da frase "Ciência da Computação tem tanto a ver com o computador como a astronomia com o telescópio […]". O projeto e desenvolvimento de computadores e sistemas computacionais são geralmente considerados disciplinas fora do contexto da Ciência da Computação. Por exemplo, o estudo do hardware é geralmente considerado parte da engenharia de computação, enquanto o estudo de sistemas computacionais comerciais são geralmente parte da tecnologia da informação ou sistemas de informação.

Por vezes a Ciência da Computação também é criticada por não ser suficientemente científica, como exposto na frase "Ciência é para a Ciência da Computação assim como a hidrodinâmica é para a construção de encanamentos", credita a Stan Kelly-Bootle.[13] Apesar disso, seu estudo frequentemente cruza outros campos de pesquisa, tais como a inteligência artifical, física e linguística.

Ela é considerada por alguns por ter um grande relacionamento com a matemática, maior que em outras disciplinas. Isso é evidenciado pelo fato que os primeiros trabalhos na área eram fortemente influenciados por matemáticos como Kurt Gödel e Alan Turing; o campo continua sendo útil para o intercâmbio de informação com áreas como lógica matemática, teoria das categorias e álgebra. Apesar disso, diferente da matemática, a Ciência da Computação é considerada uma disciplina mais experimental que teórica.

Várias alternativas para o nome da disciplina já foram cogitadas. Em francês ela é chamada informatique, em alemão Informatik, em espanhol informática, em holandês, italiano e romeno informatica, em polonês informatyka, em russo информатика e em grego Πληροφορική. Apesar disso, tanto em inglês quanto em português informática não é diretamente um sinônimo para a Ciência da Computação; o termo é usado para definir o estudo de sistemas artificiais e naturais que armazenam processos e comunicam informação, e refere-se a um conjunto de ciências da informação que engloba a Ciência da Computação. Em Portugal, no entanto, apesar de a palavra estar dicionarizada com esse sentido amplo, o termo é usado como sinónimo de Ciência da Computação.

Profissão
De forma geral, cientistas da computação estudam os fundamentos teóricos da computação, de onde outros campos derivam, como as áreas de pesquisa supracitadas. Como o nome implica, a Ciência da Computação é uma ciência pura, não aplicada. Entretanto, o profissional dessa área pode seguir aplicações mais práticas de seu conhecimento, atuando em áreas como desenvolvimento de software, telecomunicação, consultoria, análise de sistemas, segurança em TI, governança em TI, análise de negócios e tecnologia da informação. O profissional de computação precisa ter muita determinação na apreensão tecnológica, uma vez que esta área sofre contínuas transformações, modificando rapidamente paradigmas.

Ver também
Informática
Tecnologia da informação
Referências
 BROOKSHEAR, J. Gleen. Ciência da Computação: uma visão abrangente - 11º ed. Porto Alegre: Bookman, 2013.
 FEDELI, R.; POLLONI, E.; PERES, F. Introdução à Ciência da Computação. 2 ed. São Paulo: Cengage Learning, 2009.
 IFRAH, Georges (2001). The Universal History of Computing (em inglês). Nova York: John Wiley & Sons. ISBN 0-471-39671-0
 Huskey, Velma R.; Huskey, Harry D. (1980). «Lady Lovelace and Charles Babbage». Annals of The History of Computing (em inglês). 2 (4). Arlington, VA: American Federation of Information Processing Societies. 384 páginas. ISSN 1058-6180
 METROPOLIS, N. (ed.);HOWLETT, J.(ed.);ROTA, Gian-Carlo(ed.);GOOD, I. J.(Contribuidor) (1980). «Pioneering Work on Computer at Bletchley». A History of Computing in the Twentieth Century (em inglês). Nova York: Academic Press. pp. 31–45. ISBN 0-12-491650-3
 COPELAND, B. Jack (Editor) (2004). The Essential Turing. The Ideas that Gave Birth to the Computer Age. Oxford: Clarendon Press, Oxford. 613 páginas. ISBN 0-19-825079-7
 STRATHERN, Paul (1997). The Big Idea: Turing & the Computer. London: Arrow. 95 páginas. ISBN 0-09-923782-2
 SHANNON, Claude E.; WEAVER, Warren (1949). The Mathematical Theory of Communication (em inglês). Illinois: The University of Illinois Press (Illini books). pp. 3–91. Library of Congress Catalog Card Nº 49-11922
 BRETON, Philippe (1991). História da Informática. São Paulo: UNESP. pp. 52–55. ISBN 85-7139-021-5
 «Computer Science: Achievements and Challenges circa 2000» (PDF) (em inglês). Março de 2000
 Hal Abelson, G.J. Sussman, J.Sussman (1996). Structure and Interpretation of Computer Programs 2 ed. [S.l.]: MIT Press. ISBN 0-262-01153-0
 Ghallab, M., Nau, D. S., and Traverso, P. (2004). Automated Planning: Theory and Practice. ISBN 1-55860-856-7
 Computer Language, outubro de 1990
Ligações externas
Fundamentos em informática
Outros projetos Wikimedia também contêm material sobre este tema:
Wikilivros	Livros e manuais no Wikilivros
Commons	Categoria no Commons
Wikiversidade	Cursos na Wikiversidade
Análise de sistemas e tecnologia da informação
Lista de termos de computação
Engenharia de computação
Engenharia Informática
Sistema de informação
Informática
Problemas em aberto da Ciência da computação
Computação afetiva

[Expandir]vde
Tópicos de Ciência da computação
[Expandir]vde
Tópicos sobre computação
[Expandir]vde
Engenharia de software
Controle de autoridade	
Wd: Q21198AAT: 300054575BNCF: 1576BNE: XX525961BNF: 11932109bBRE: 5095752EBID: IDGND: 4026894-9HDS: 008272JSTOR: computer-science-educationLCCN: sh89003285Treccani: informatica
Categorias: Ciência da computaçãoCiências exatas
Esta página foi editada pela última vez às 22h45min de 28 de novembro de 2021.
Este texto é disponibilizado nos termos da licença Atribuição-CompartilhaIgual 3.0 Não Adaptada (CC BY-SA 3.0) da Creative Commons; pode estar sujeito a condições adicionais. Para mais detalhes, consulte as condições de utilização.
Política de privacidadeSobre a WikipédiaAvisos geraisVersão móvelProgramadoresEstatísticasDeclaração sobre ''cookies''Wikimedia FoundationPowered by MediaWiki